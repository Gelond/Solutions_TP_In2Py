{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                  Le module BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "# Introduction :\n",
    "\n",
    "BeautifulSoup est une bibliothèque Python d'analyse syntaxique de documents HTML et XML créée par Leonard Richardson.\n",
    "La dernière version est le 4.9.1 (17 mai 2020)\n",
    "\n",
    "Elle produit un arbre syntaxique qui peut être utilisé pour chercher des éléments ou les modifier en transformant\n",
    "un document HTML complexe en un arbre d'objets Python.\n",
    "\n",
    "Pour être plus précis, l’arbre est constitué de quatre types d’objets, Tag,\n",
    "NavigableString, BeautifulSoup et Comment. Cet arbre peut ensuite être \"interrogé\" en utilisant les\n",
    "méthodes / propriétés de l'objet BeautifulSoup créé à partir de la bibliothèque de l'analyseur.\n",
    "\n",
    "Cette bibliothèque python permet d’extraire des informations d’un site web, ou encore d’un document XML, avec\n",
    "quelques lignes de code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Besoins :\n",
    "\n",
    "Vous avez souvent l'un des besoins suivants:\n",
    "1. Vous souhaiterez peut-être analyser une page Web pour déterminer le nombre de balises\n",
    "trouvées, le nombre d'éléments de chaque balise détectés et leurs valeurs. Vous voudrez\n",
    "peut-être les changer.\n",
    "2. Vous souhaiterez peut-être déterminer les noms et les valeurs des éléments afin de pouvoir\n",
    "les utiliser conjointement avec d'autres bibliothèques pour l'automatisation de pages Web,\n",
    "telles que Selenium .\n",
    "3. Vous pouvez souhaiter transférer / extraire des données affichées dans une page Web vers\n",
    "d'autres formats, tels qu'un fichier CSV ou une base de données relationnelle telle que\n",
    "SQLite ou mysql. Dans ce cas, la bibliothèque vous aide dans la première étape, à\n",
    "comprendre la structure de la page Web, bien que vous utilisiez d'autres bibliothèques pour\n",
    "effectuer l'acte de transfert.\n",
    "4. Vous voudrez peut-être savoir combien d’éléments sont stylés avec un certain style CSS et\n",
    "lesquels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation :\n",
    "\n",
    "La commande suivante permet d'installer la bibliothèque BeautifulSoup de Python qui devrait fonctionner sur Python 2 et Python 3:\n",
    "\n",
    "$ pip install beautifulsoup4\n",
    "\n",
    "Si vous n'avez pas de pip installé sur votre système, vous pouvez télécharger directement la tablette source Beautiful Soup 4 et l'installer à l'aide de setup.py.\n",
    "\n",
    "$ python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreurs possibles :\n",
    "\n",
    "- Le \"Aucun module nommé HTMLParser\" ImportError se produit lorsque vous exécutez la version Python 2 du code sous Python 3.\n",
    "- Le \"Aucun module nommé html.parser\" ImportError se produit lorsque vous exécutez la version Python 3 du code sous Python 2.\n",
    "\n",
    "Les deux erreurs ci-dessus peuvent être corrigées en désinstallant et en réinstallant Beautiful Soup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation d'un analyseur :\n",
    "\n",
    "L'objet BeautifulSoup peut accepter deux arguments. Le premier argument est le marquage actuel, et le second argument est l'analyseur que vous souhaitez utiliser. Les différents analyseurs sont: html.parser, lxml et html5lib. L'analyseur lxml comporte deux versions, un analyseur HTML et un analyseur XML.\n",
    "\n",
    "Le html.parser est un analyseur intégré, et cela ne fonctionne pas si bien dans les anciennes versions de Python. Vous pouvez installer les autres analyseurs à l'aide des commandes suivantes:\n",
    "\n",
    "\n",
    "$ pip install lxml\n",
    "\n",
    "\n",
    "$ pip install html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyseur lxml est très rapide et peut être utilisé pour analyser rapidement le HTML. D'autre part, l'analyseur html5lib est très lent, mais il est également extrêmement indulgent. Voici un exemple d'utilisation de chacun de ces analyseurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><p>This is <b>invalid HTML</b></p></html>\n",
      "<html><head></head><body><p>This is <b>invalid HTML</b></p></body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    " \n",
    "soup = BeautifulSoup(\"<html><p>This is <b>invalid HTML</p></html>\", \"html.parser\")\n",
    "print(soup)\n",
    "# <html><p>This is <b>invalid HTML</b></p></html>\n",
    " \n",
    "\n",
    "soup = BeautifulSoup(\"<html><p>This is <b>invalid HTML</p></html>\", \"html5lib\")\n",
    "print(soup)\n",
    "# <html><head></head><body><p>This is <b>invalid HTML</b></p></body></html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple de grattage BeautifulSoup :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "#Histoire\n",
      "#Utilité\n",
      "#Programmes_Hello_world!\n",
      "#Notes_et_références\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "main_url = \"https://fr.wikipedia.org/wiki/Hello_world\"\n",
    "req = requests.get(main_url)\n",
    "soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "# Finding the main title tag.\n",
    "\n",
    "title = soup.find(\"h1\", class_ = \"firstHeading\")\n",
    "print (title.get_text())\n",
    "\n",
    "# Finding the mid-titles tags and storing them in a list.\n",
    "\n",
    "mid_titles = [tag.get_text() for tag in soup.find_all(\"span\", class_ = \"mw-headline\")]\n",
    "\n",
    "# Now using css selectors to retrieve the article shortcut links\n",
    "\n",
    "links_tags = soup.select(\"li.toclevel-1\")\n",
    "for tag in links_tags:\n",
    "    print (tag.a.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les méthodes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Différentes méthodes peuvent être utilisées pour trouver un élément dans l'arborescence de la\n",
    "page Web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Éléments de localisation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".next_sibling\n",
    "\n",
    "\n",
    "Localiser un texte après un élément dans BeautifulSoup :\n",
    "\n",
    "Imaginez que vous avez le code HTML suivant et vous voulez localiser le texte \"John Smith\" après l'élément label.\n",
    "Dans ce cas, vous pouvez localiser l'élément label par texte, puis utiliser la propriété .next_sibling\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Smith\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = \"\"\"\n",
    "<div>\n",
    "<label>Name:</label>\n",
    "John Smith\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "label = soup.find(\"label\", text=\"Name:\")\n",
    "print(label.next_sibling.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de sélecteurs CSS pour localiser des éléments dans BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item1\n",
      "item2\n",
      "item3\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = \"\"\"\n",
    "<ul>\n",
    "<li class=\"item\">item1</li>\n",
    "<li class=\"item\">item2</li>\n",
    "<li class=\"item\">item3</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "for item in soup.select(\"li.item\"):\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Localisation des commentaires\n",
    "\n",
    "Pour localiser les commentaires dans BeautifulSoup , utilisez l'argument text (ou string dans les\n",
    "versions récentes) vérifiant le type à Comment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " desired text \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from bs4 import Comment\n",
    "\n",
    "data = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<div>\n",
    "<!-- desired text -->\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "comment = soup.find(text=lambda text: isinstance(text, Comment))\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de filtrage\n",
    "\n",
    "BeautifulSoup vous permet de filtrer les résultats en fournissant une fonction à find_all et à des\n",
    "fonctions similaires. Cela peut être utile pour les filtres complexes ainsi que pour un outil de\n",
    "réutilisation du code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de base :\n",
    "    \n",
    "Définir une fonction qui prend un élément comme seul argument. La fonction doit retourner True si\n",
    "l'argument correspond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns True for tags with a href attribute\n",
    "def has_href(tag):\n",
    "  \n",
    "    return bool(tag.get(\"href\"))\n",
    "\n",
    "soup.find_all(has_href) #find all elements with a href attribute\n",
    "\n",
    "#equivilent using lambda:\n",
    "\n",
    "soup.find_all(lambda tag: bool(tag.get(\"href\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer le contenu d'une balise spécifiée\n",
    "\n",
    "BeautifulSoup vous propose par exemple de récupérer toutes les balises p d'une page HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Texte à lire 1</p>\n",
      "<p>Texte à lire 2</p>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "    <title>Titre de votre site</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>Texte à lire 1</p>\n",
    "        <p>Texte à lire 2</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "for p in soup.find_all('p'):\n",
    "    print (p)\n",
    "\n",
    "soup.find_all(has_href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Changer le contenu de balises\n",
    "\n",
    "Trouver les éléments qui nous intéresse c'est une chose, mais pouvoir les modifier c'est encore mieux! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Titre de votre site</title>\n",
      "</head>\n",
      "<body>\n",
      "<p>Nouveau texte</p>\n",
      "<p>Nouveau texte</p>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "    <title>Titre de votre site</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>Texte à lire 1</p>\n",
    "        <p>Texte à lire 2</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "for p in soup.find_all('p'):\n",
    "    p.string = \"Nouveau texte\"\n",
    "    \n",
    "print (soup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Remplacer des balises\n",
    "\n",
    "Vous pouvez remplacer les balises avec la méthode replace_with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Titre de votre site</title>\n",
      "</head>\n",
      "<body>\n",
      "<pre>Texte à lire 1</pre>\n",
      "<pre>Texte à lire 2</pre>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "    <title>Titre de votre site</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>Texte à lire 1</p>\n",
    "        <p>Texte à lire 2</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "for p in soup.find_all('p'):\n",
    "    n = BeautifulSoup('<pre>%s</pre>' % p.string)\n",
    "    p.replace_with(n.body.contents[0])\n",
    "    \n",
    "print (soup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire les attributs\n",
    "\n",
    "Il est possible de lire les attributs des éléments avec la méthode get :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1', 'c2']\n",
      "['c3']\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "    <title>Titre de votre site</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"c1 c2\">Texte à lire 1</p>\n",
    "        <p class=\"c3\">Texte à lire 2</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "for p in soup.find_all('p'):\n",
    "    print (p.get(\"class\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les méthodes de la classe BeautifulSoup\n",
    "\n",
    "- clear( decompose=False )\n",
    "\n",
    "Extrait tous les enfants\n",
    "\n",
    "- decode_contents ( indent_level=None, eventual_encoding='utf-8', formatter='minimal' )\n",
    "\n",
    "Créer un rendu en chaine unicode\n",
    "\n",
    "- decompose()\n",
    "\n",
    "Detruit récursivement les contenus de l'arbre\n",
    "\n",
    "- encode ( encoding='utf-8', indent_level=None, formatter='minimal', errors='xmlcharrefreplace' )\n",
    "\n",
    "encode\n",
    "\n",
    "- encode_contents ( indent_level=None, encoding='utf-8', formatter='minimal' )\n",
    "\n",
    "Créer des rendus du tag en bytestring\n",
    "\n",
    "- find ( name=None, attrs={}, recursive=True, text=None, **kwargs )\n",
    "\n",
    "Retourne seulement le premier enfant de la balise correspondant pour le critère donné\n",
    "\n",
    "- find_all ( name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne une liste d'objet balise correspondant à la demande.\n",
    "\n",
    "- find ( name=None, attrs={}, recursive=True, text=None, **kwargs )\n",
    "\n",
    "Retourne seulement le premier enfant de la balise cherchée\n",
    "\n",
    "- findChildren ( name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne une liste d'objet balise correspondant à la demande\n",
    "\n",
    "- get ( key, default=None )\n",
    "\n",
    "Retourne la valeur de l'attribut \"key\" de la balise ou retourne la valeur default\n",
    "\n",
    "- get_text ( self, separator=u'', strip=False, types=( <class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'> ) )\n",
    "\n",
    "Retourne toutes les chaines de caractères des enfants concaténé utilisant le séparateur indiqué\n",
    "\n",
    "- has_attr ( key )\n",
    "\n",
    "True si l'attribut demandé est présent\n",
    "\n",
    "- has_key ( key )\n",
    "\n",
    "Vérifie la présence de la clé\n",
    "\n",
    "- index ( element )\n",
    "\n",
    "Retourne l'index de l'élément\n",
    "\n",
    "- prettify ( self, encoding=None, formatter='minimal' )\n",
    "\n",
    "Améliore la lecture du code\n",
    "\n",
    "- recursiveChildGenerator ( )\n",
    "\n",
    "- append ( self, tag )\n",
    "\n",
    "Ajoute la balise donnée à l'objet en cours\n",
    "\n",
    "- extract ( )\n",
    "\n",
    "Extrait l'élément de l'arbre\n",
    "\n",
    "- find_next_siblings ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Renvoi les objects frères de l'objet en cours\n",
    "\n",
    "- find_parents ( self, name=None, attrs={}, limit=None, **kwargs )\n",
    "\n",
    "Renvoi les parents\n",
    "\n",
    "- find_all_previous ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne tous les items qui match avec le critère donné avant l'objet en cours\n",
    "\n",
    "- find_previous_siblings ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne les objets frères de l'objet en cours qui sont avant celui-ci\n",
    "\n",
    "- find_all_next ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne les objets qui correpondent à la recherche mais qui se situent après l'objet en cours\n",
    "\n",
    "- find_all_previous ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne les objets qui correspondent à la recherche mais qui se situent avant l'objet en cours\n",
    "\n",
    "- find_next ( self, name=None, attrs={}, text=None, **kwargs )\n",
    "\n",
    "Retourne le premier objet frère après l'objet en cours\n",
    "\n",
    "- find_next_sibling ( self, name=None, attrs={}, text=None, **kwargs )\n",
    "\n",
    "Retourne l'objet frère le plus proche après lui\n",
    "\n",
    "- find_next_siblings ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne les objets frères suivants\n",
    "\n",
    "- find_parent ( self, name=None, attrs={}, **kwargs )\n",
    "\n",
    "Retourne le parent le plus proche\n",
    "\n",
    "- find_parents ( self, name=None, attrs={}, limit=None, **kwargs )\n",
    "\n",
    "Retourne les parents\n",
    "\n",
    "- find_previous ( self, name=None, attrs={}, text=None, **kwargs )\n",
    "\n",
    "Retourne le premier item avant l'objet en cours\n",
    "\n",
    "- find_previous_sibling ( self, name=None, attrs={}, text=None, **kwargs )\n",
    "\n",
    "Retourne l'item frère le plus proche précédent l'objet en cours\n",
    "\n",
    "- find_previous_siblings ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne les items frères les plus proches précédents l'objet en cours\n",
    "\n",
    "- find_all_next ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne tous les items qui suivent l'objet en cours\n",
    "\n",
    "- find_all_previous ( self, name=None, attrs={}, text=None, limit=None, **kwargs )\n",
    "\n",
    "Retourne tous les items qui précédent l'objet en cours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation\n",
    "\n",
    "J'avais besoin d'un parseur HTML pour mettre en forme et colorer le code que je présente sur ce site; je partage ce petit script: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "#import pandas as pd\n",
    "\n",
    "url = \"https://feeds.bbci.co.uk/news/rss.xml\"\n",
    "\n",
    "#Importer le code de la page\n",
    "\n",
    "reponse = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(reponse.text, \"html.parser\")\n",
    "\n",
    "items = soup.findAll('item')\n",
    "#print(items[0])\n",
    "it = items[0]\n",
    "\n",
    "#print(it.description.text)\n",
    "\n",
    "new_it = []\n",
    "\n",
    "new_i = {}\n",
    "\n",
    "for i in items:\n",
    "    new_i['title'] = it.title.text\n",
    "    new_i['description'] = it.description.text\n",
    "    new_i['pubdate'] = it.pubdate.text\n",
    "    new_it.append(new_i)\n",
    "    \n",
    "#for i in new_it:\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
